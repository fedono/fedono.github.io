## TCP/IP

因特网有两个核心协议:IP 和 TCP。IP，即 Internet Protocol(因特网协议)，负 责联网主机之间的路由选择和寻址;TCP，即 Transmission Control Protocol(传输 控制协议)，负责在不可靠的传输信道之上提供可靠的抽象层。TCP/IP 也常被称为“因特网协议套件”(Internet Protocol Suite)，

TCP 负责在不可靠的传输信道之上提供可靠的抽象层，向应用层隐藏了大多数网络 通信的复杂细节，比如丢包重发、按序发送、拥塞控制及避免、数据完整，等等。

![image-20201112100738870](../assets/imgs/web-performance-difinite-guide/connect.png)

• SYN

客户端选择一个随机序列号 *x*，并发送一个 SYN 分组，其中可能还包括其他 TCP 标志和选项。

• SYN ACK

服务器给 *x* 加 1，并选择自己的一个随机序列号 *y*，追加自己的标志和选项，然 后返回响应。

• ACK

客户端给 *x* 和 *y* 加 1 并发送握手期间的最后一个 ACK 分组。

TCP 在不可靠的信道上实现了可靠的网络传输。基本的分组错误检测与纠正、按 序交付、丢包重发，以及保证网络最高效率的流量控制、拥塞控制和预防机制，让 TCP 成为大多数网络应用中最常见的传输协议。

虽然 TCP 很流行，但它并不是唯一的选择，而且在某些情况下也不是最佳的选择。 特别是按序交付和可靠交付有时候并不必要，反而会导致额外的延迟，对性能造成 负面影响。

要理解为什么，可以想一想，每个 TCP 分组都会带着一个唯一的序列号被发出，而 所有分组必须按顺序传送到接收端(图 2-8)。如果中途有一个分组没能到达接收 端，那么后续分组必须保存在接收端的 TCP 缓冲区，等待丢失的分组重发并到达接 收端。这一切都发生在 TCP 层，应用程序对 TCP 重发和缓冲区中排队的分组一无所 知，必须等待分组全部到达才能访问数据。在此之前，应用程序只能在通过套接字 读数据时感觉到延迟交付。这种效应称为 TCP 的队首(HOL，Head of Line)阻塞。

## 无协议服务

要理解为什么 UDP 被人称作“无协议”，必须从作为 TCP 和 UDP 下一层的 IP 协议

说起。

IP 层的主要任务就是按照地址从源主机向目标主机发送数据报。为此，消息会被封 装在一个 IP 分组内(图 3-1)，其中载明了源地址和目标地址，以及其他一些路由参 数。注意，数据报这个词暗示了一个重要的信息:IP 层不保证消息可靠的交付，也 不发送失败通知，实际上是把底层网络的不可靠性直接暴露给了上一层。如果某个 路由节点因为网络拥塞、负载过高或其他原因而删除了 IP 分组，那么在必要的情况 下，IP 的上一层协议要负责检测、恢复和重发数据。

![image-20201112105654875](../assets/imgs/web-performance-difinite-guide/header-of-IPv4.png)

UDP 协议会用自己的分组结构(图 3-2)封装用户消息，它只增加了 4 个字段:源 端口、目标端口、分组长度和校验和。这样，当 IP 把分组送达目标主机时，该主机 能够拆开 UDP 分组，根据目标端口找到目标应用程序，然后再把消息发送过去。仅 此而已。

![image-20201112105737172](../assets/imgs/web-performance-difinite-guide/header-of-udp.png)

事实上，UDP 数据报中的源端口和校验和字段都是可选的。IP 分组的首部也有校验 和，应用程序可以忽略 UDP 校验和。也就是说，所有错误检测和错误纠正工作都可 以委托给上层的应用程序。说到底，UDP 仅仅是在 IP 层之上通过嵌入应用程序的 源端口和目标端口，提供了一个“应用程序多路复用”机制。明白了这一点，就可 以总结一下 UDP 的无服务是怎么回事了。

- 不保证消息交付 

  不确认，不重传，无超时。

- 不保证交付顺序 

  不设置包序号，不重排，不会发生队首阻塞。

- 不跟踪连接状态 

  不必建立连接或重启状态机。

- 不需要拥塞控制 

  不内置客户端或网络反馈机制。

TCP 是一个面向字节流的协议，能够以多个分组形式发送应用程序消息，且对分组 中的消息范围没有任何明确限制。因此，连接的两端存在一个连接状态，每个分组 都有序号，丢失还要重发，并且要按顺序交付。相对来说，UDP 数据报有明确的限 制:数据报必须封装在 IP 分组中，应用程序必须读取完整的消息。换句话说，数据 报不能分片。

UDP 是一个简单、无状态的协议，适合作为其他上层应用协议的辅助。实际上，这 个协议的所有决定都需要由上层的应用程序作出。不过，在急着去实现一个协议来 扮演 TCP 的角色之前，你还应该认真想一想这里涉及的复杂细节，比如 UDP 要与 很多中间设备打交道(NAT 穿透)，再想一想设计网络协议的那些最佳实践。如果 没有周密的设计和规划，一流的构想也可能沦为二流的 TCP 实现。TCP 中的算法和 状态机已经经过了几十年的磨合与改进，而且吸收几十种并不那么容易重新实现的 机制。



## TLS握手

SSL 2.0 是该协议第一个公开发布的版本，但由于存在很多安全缺陷很快就被 SSL 3.0 取代。鉴于 SSL 协议是网景公司专有的，IETF 成立了一个小组负责标准化该协 议，后来就有了 RFC 2246，即 TLS 1.0，也就是 SSL 3.0 的升级版。

客户端与服务器在通过 TLS 交换数据之前，必须协商建立加密信道。协商内容包括 TLS 版本、加密套件，必要时还会验证证书。然而，协商过程的每一步都需要一个 分组在客户端和服务器之间往返一次(图 4-2)，因而所有 TLS 连接启动时都要经历 一定的延迟。

![image-20201112111751910](../assets/imgs/web-performance-difinite-guide/tls-protocol.png)

- 0 ms:TLS 在可靠的传输层(TCP)之上运行，这意味着首先必须完成 TCP 的“三 次握手”，即一次完整的往返。
- 56 ms:TCP 连接建立之后，客户端再以纯文本形式发送一些规格说明，比如它所运 行的 TLS 协议的版本、它所支持的加密套件列表，以及它支持或希望使用的另外一 些 TLS 选项。
- 84 ms:然后，服务器取得 TLS 协议版本以备将来通信使用，从客户端提供的加密 套件列表中选择一个，再附上自己的证书，将响应发送回客户端。作为可选项，服 务器也可以发送一个请求，要求客户端提供证书以及其他 TLS 扩展参数。
- 112 ms:假设两端经过协商确定了共同的版本和加密套件，客户端也高高兴兴地 把自己的证书提供给了服务器。然后，客户端会生成一个新的对称密钥，用服务 器的公钥来加密，加密后发送给服务器，告诉服务器可以开始加密通信了。到 目前为止，除了用服务器公钥加密的新对称密钥之外，所有数据都以明文形式 发送。
- 140 ms:最后，服务器解密出客户端发来的对称密钥，通过验证消息的 MAC 检 测消息完整性，再返回给客户端一个加密的“Finished”消息。
- 168 ms:客户端用它之前生成的对称密钥解密这条消息，验证 MAC，如果一切 顺利，则建立信道并开始发送应用数据。

## HTTP

HTTP 1.x 的设计初衷主要是实现要简单:HTTP 0.9 只用一行协议就启动了万维网; HTTP 1.0 则是对流行的 0.9 扩展的一个正式说明;HTTP 1.1 则是 IETF 的一份官方 标准(参见第 9 章)。因此，HTTP 0.9~1.x 只描述了现实是怎么一回事:HTTP 是应 用最广泛、采用最多的一个互联网应用协议。

- HTTP 0.9:只有一行的协议

1991 年Tim Berners-Lee 概述了这个新协议的动机，并罗列了几条宏观的设计目 标:支持文件传输、能够请求对超文本文档的索引搜索、格式化协商机制，以及能 够把客户端引导至不同的服务器。

1996 年， HTTP 工作组发布了 RFC 1945，解释说明了当时很多 HTTP 1.0 实现的“公共用 法”。不过，据我们所知，这个 RFC 只是参考性的。HTTP 1.0 并不是一个正式的规 范或互联网标准!

-  HTTP 1.0 协议的关键 变化:

• 请求可以由于多行首部字段构成;
 • 响应对象前面添加了一个响应状态行;
 • 响应对象也有自己的由换行符分隔的首部字段;
 • 响应对象不局限于超文本;
 • 服务器与客户端之间的连接在每次请求之后都会关闭。

HTTP 1.0 对每个请求都打开一个新 TCP 连接严重影响性能

- HTTP 1.1:互联网标准

HTTP 1.1 标准厘清了之前版本中很多有歧义的地方，而且还加入了很多重要的性能 优化:持久连接、分块编码传输、字节范围请求、增强的缓存机制、传输编码及请 求管道。

➊ 请求 HTML 文件，及其编码、字符集和元数据
 ➋ 对原始 HTML 请求的分块响应
 ➌ 以 ASCII 十六进制数字表示的分块数据的字节数(256 字节) ➍ 分块数据流响应结束
 ➎ 在同一个 TCP 连接上请求图标文件
 ➏ 通知服务器不再使用连接了
 ➐ 图标响应，随后关闭连接

HTTP 1.1 改变了 HTTP 协议的语义，默认使用持久连接。换句话说，除 非明确告知(通过 Connection: close 首部)，否则服务器默认会保持连 接打开。
 不过，这个功能也反向移植到了 HTTP 1.0，可以通过 Connection: Keep- Alive 首部来启用。实际上，如果你使用的是 HTTP 1.1，从技术上说不需 要 Connection: Keep-Alive 首部，但很多客户端还是选择加上它。

- HTTP 2.0:改进传输性能

HTTP 2.0 的主要目标是改进传输性能，实现低延迟和高吞吐量。

HTTP 2.0 的目的就是通过支持请求与响应的多路复用来减少延迟，通过压缩 HTTP 首部字段将协议开销降至最低，同时增加对请求优先级和服务器端推送的支持。为 达成这些目标，HTTP 2.0 还会给我们带来大量其他协议层面的辅助实现，比如新的 流量控制、错误处理和更新机制。上述几种机制虽然不是全部，但却是最重要的， 所有 Web 开发者都应该理解并在自己的应用中利用它们。

HTTP 2.0 不会改动 HTTP 的语义。HTTP 方法、状态码、URI 及首部字段，等等这 些核心概念一如往常。但是，HTTP 2.0 修改了格式化数据(分帧)的方式，以及客 户端与服务器间传输这些数据的方式。这两点统帅全局，通过新的组帧机制向我们 的应用隐藏了所有复杂性。换句话说，所有原来的应用都可以不必修改而在新协议 运行。这当然是好事。

有必要回顾一下 HTTP 2.0 宣言草稿，因为这份宣言明确了该协议的范围和 关键设计要求:

HTTP/2.0 应该满足如下条件:

- 相对于使用 TCP 的 HTTP 1.1，用户在大多数情况下的感知延迟要有实质上、 可度量的改进;

- 解决 HTTP 中的“队首阻塞”问题;

- 并行操作无需与服务器建立多个连接，从而改进 TCP 的利用率，特别是拥塞

  控制方面;

- 保持 HTTP 1.1 的语义，利用现有文档，包括(但不限于)HTTP 方法、状态码、

  URI，以及首部字段;

- 明确规定 HTTP 2.0 如何与 HTTP 1.x 互操作，特别是在中间介质上;

- 明确指出所有新的可扩展机制以及适当的扩展策略。

  对现有的 HTTP 部署——特别是 Web 浏览器(桌面及移动)、非浏览器(“HTTP API”)、Web 服务(各种规模)，以及中间介质(代理、公司防火墙、“反向” 代理及 CDN)而言，最终规范应该满足上述这些目标。类似地，当前和未 来对 HTTP/1.x 的语义扩展(如首部、方法、状态码、缓存指令)也应该得 到新协议的支持。

  ——HTTPbis WG 宣言 HTTP 2.0

简言之，HTTP 2.0 致力于突破上一代标准众所周知的性能限制，但它也是对之前 1.x 标准的扩展，而非替代。HTTP 的语义不变，提供的功能不变，HTTP 方法、状 态码、URI 和首部字段，等等这些核心概念也不变;这些方面的变化都不在考虑之 列。既然如此，那“2.0”还名副其实吗?

之所以要递增一个大版本到 2.0，主要是因为它改变了客户端与服务器之间交换数据 的方式。为实现宏伟的性能改进目标，HTTP 2.0 增加了新的二进制分帧数据层，而 这一层并不兼容之前的 HTTP 1.x 服务器及客户端——是谓 2.0。

HTTP/2.0 通过支持首部字段压缩和在同一连接上发送多个并发消息，让应 用更有效地利用网络资源，减少感知的延迟时间。而且，它还支持服务器到 客户端的主动推送机制。

**流、消息和帧**

新的二进制分帧机制改变了客户端与服务器之间交互数据的方式(图 12-2)。为了

说明这个过程，我们需要了解 HTTP 2.0 的两个新概念。 •流

已建立的连接上的双向字节流。

• 消息 与逻辑消息对应的完整的一系列数据帧。

•帧
 HTTP 2.0 通信的最小单位，每个帧包含帧首部，至少也会标识出当前帧所属的流。

![image-20201112145601667](../assets/imgs/web-performance-difinite-guide/http2.png)

所有 HTTP 2.0 通信都在一个连接上完成，这个连接可以承载任意数量的双向数据

流。相应地，每个数据流以消息的形式发送，而消息由一或多个帧组成，这些帧可 以乱序发送，然后再根据每个帧首部的流标识符重新组装。

HTTP 2.0 的所有帧都采用二进制编码，所有首部数据都会被压缩。因此， 图 12-2 只是说明了数据流、消息和帧之间的关系，而非它们实际传输时的 编码结果

这简简单单的几句话里浓缩了大量的信息，我们再重申一次。要理解 HTTP 2.0，就 必须理解流、消息和帧这几个基本概念。

- 所有通信都在一个 TCP 连接上完成。

- 流是连接中的一个虚拟信道，可以承载双向的消息;每个流都有一个唯一的整数

  标识符(1、2...*N*)。

- 消息是指逻辑上的 HTTP 消息，比如请求、响应等，由一或多个帧组成。

- 帧是最小的通信单位，承载着特定类型的数据，如 HTTP 首部、负荷，等等。

  简言之，HTTP 2.0 把 HTTP 协议通信的基本单位缩小为一个一个的帧，这些帧对应 着逻辑流中的消息。相应地，很多流可以并行地在同一个 TCP 连接上交换消息。

### 多向请求与响应

在 HTTP 1.x 中，如果客户端想发送多个并行的请求以及改进性能，那么必须使用 多个 TCP 连接(参见 11.3 节“使用多个 TCP 连接”)。这是 HTTP 1.x 交付模型的 直接结果，该模型会保证每个连接每次只交付一个响应(多个响应必须排队)。更糟 糕的是，这种模型也会导致队首阻塞，从而造成底层 TCP 连接的效率低下。

HTTP 2.0 中新的二进制分帧层突破了这些限制，实现了多向请求和响应:客户端和 服务器可以把 HTTP 消息分解为互不依赖的帧(图 12-3)，然后乱序发送，最后再 在另一端把它们重新组合起来。

把 HTTP 消息分解为独立的帧，交错发送，然后在另一端重新组装是 HTTP 2.0 最 重要的一项增强。事实上，这个机制会在整个 Web 技术栈中引发一系列连锁反应， 从而带来巨大的性能提升，因为:

- 可以并行交错地发送请求，请求之间互不影响;

- 可以并行交错地发送响应，响应之间互不干扰;

- 只使用一个连接即可并行发送多个请求和响应;

- 消除不必要的延迟，从而减少页面加载的时间;

- 不必再为绕过 HTTP 1.x 限制而多做很多工作;

- 更多优势。

  总之，HTTP 2.0 的二进制分帧机制解决了 HTTP 1.x 中存在的队首阻塞问题，也消 除了并行处理和发送请求及响应时对多个连接的依赖。结果，就是应用速度更快、 开发更简单、部署成本更低。

支持多向请求与响应，可以省掉针对 HTTP 1.x 限制所费的那些脑筋和工 作，比如拼接文件、图片精灵、域名分区(参见 13.2 节“针对 HTTP 1.x 的优化建议”)。类似地，通过减少 TCP 连接的数量，HTTP 2.0 也会减少 客户端和服务器的 CPU 及内存占用。

### 请求优先级

把 HTTP 消息分解为很多独立的帧之后，就可以通过优化这些帧的交错和传输顺序，

进一步提升性能。为了做到这一点，每个流都可以带有一个 31 比特的优先值:

1. - 0 表示最高优先级;

2. - 2的32次方-1 表示最低优先级

有了这个优先值，客户端和服务器就可以在处理不同的流时采取不同的策略，以最 优的方式发送流、消息和帧。具体来讲，服务器可以根据流的优先级，控制资源分 配(CPU、内存、带宽)，而在响应数据准备好之后，优先将最高优先级的帧发送给 客户端。

> 不再复制了，直接去看《web性能权威指南》的 HTTP 这一章就好，这一章的 http2 还是讲的不错的。